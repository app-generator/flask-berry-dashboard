{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://medium.com/@rami.krispin/setting-a-natural-language-to-sql-code-generator-with-python-d267f40d7218"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current issue is that while we have successfully tested our Bedrock GenAI PoC RAG model (with Antjropic CLuade LLM) or the LDFE job status report to query around forecast anomalies in natural language, there is a tendency to hallucinate in the response (even with temperature 0 and 1) and fundamental questions such as hoe many forecasts were run last night, how many succeeded, failed etc. with or without a specific error message or anomaly are not satisfactory.\n",
    "\n",
    "This notebook is to test how to: query in natural lanaguage the job status report, then convert into a SQL query (potentially using AI or GenAI with an LLM) to return the desired query result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mysql.connector\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import create_sql_prompt as csp\n",
    "\n",
    "import os\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_host = os.getenv(\"RDS_HOST\")\n",
    "local_user = os.getenv(\"RDS_USER\")\n",
    "local_pwd = os.getenv(\"RDS_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(host=local_host, \n",
    "                               user=local_user, \n",
    "                               password=local_pwd, \n",
    "                               database=\"rr_core\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create SQL Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *check* below needs to understand fail or failed\n",
    "\n",
    "# BELOW QUESTIONS THAT SHOULD BE ANSWERABLE\n",
    "\n",
    "# query = \"Hello, how are you ?\"\n",
    "\n",
    "# query = \"How many inference jobs fail on 14th Jun 2024 ?\"\n",
    "\n",
    "query = \"How many inference jobs failed this morning\"\n",
    "# query = \"What is the main anomaly in the data\"\n",
    "# query = \"What was the main anomaly in inference jobs today\"\n",
    "# query = \"What has been the main forecast error recently\"\n",
    "\n",
    "# query = \"What % of jobs succeeded versus failed in the last 7 days\"\n",
    "# query = \"What has been the trend in failed v. successful runs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barry.walsh/rotaready/rr_repos/ML-LabourDemandForecasting/notebooks/GenAI/create_sql_prompt.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  tbl_describe = pd.read_sql_query(\"select * from ldfe_jobs\", con=conn)\n"
     ]
    }
   ],
   "source": [
    "# formulate OpenAI prompt\n",
    "prompt = csp.create_message(conn, query = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given the following SQL table, your job is to write queries given a user's request. \n",
      "\n",
      "    Please consider verbs with all their tenses and any dates mentioned default to this year unless specified.\n",
      "\n",
      "    CREATE TABLE `ldfe_jobs` (`id` int(11) unsigned NOT NULL AUTO_INCREMENT,\n",
      "                    `timestamp` timestamp NOT NULL DEFAULT NULL,\n",
      "                    `realm` varchar(40) NOT NULL,\n",
      "                    `site` varchar(4) COLLATE utf8mb4_unicode_ci NOT NULL,\n",
      "                    `jobtype` varchar(40) NOT NULL,\n",
      "                    `status` ENUM('success', 'fail'),\n",
      "                    `note` varchar(500) DEFAULT NULL,\n",
      "                    `fail reason` varchar(500) DEFAULT NULL,\n",
      "                    PRIMARY KEY (`id`)) \n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt.system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform prompt into OpenAI format\n",
    "converted_message = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": prompt.system\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt.user\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = converted_message,\n",
    "        temperature = 0.3,\n",
    "        max_tokens = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9bQlrbNcxghaMzzPz6gNGx4OrSSKZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"```sql\\nSELECT COUNT(*) AS num_failed_jobs\\nFROM ldfe_jobs\\nWHERE DATE(timestamp) = CURDATE()\\nAND status = 'fail'\\n```\", role='assistant', function_call=None, tool_calls=None))], created=1718708071, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=31, prompt_tokens=182, total_tokens=213))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```sql\\nSELECT COUNT(*) AS num_failed_jobs\\nFROM ldfe_jobs\\nWHERE DATE(timestamp) = CURDATE()\\nAND status = 'fail'\\n```\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract sql query from response\n",
    "sql = response.choices[0].message.content\n",
    "sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sql\\nSELECT COUNT(*) AS num_failed_jobs\\nFROM ldfe_jobs\\nWHERE DATE(timestamp) = CURDATE()\\nAND status = 'fail'\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = sql.replace(\"```\", \"\") # get rid of ``` in query\n",
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT COUNT(*) AS num_failed_jobs\\nFROM ldfe_jobs\\nWHERE DATE(timestamp) = CURDATE()\\nAND status = 'fail'\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = sql[4:] # remove first 5 characters i.e. sql\\n\n",
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/ysrkn8dn65b6bsvj1sb28p9m0000gp/T/ipykernel_41899/2713898106.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result = pd.read_sql_query(sql, con=conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_failed_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_failed_jobs\n",
       "0               83"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the OpenAI generated SQL query\n",
    "# \n",
    "result = pd.read_sql_query(sql, con=conn)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow-on tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select count(*) \n",
    "                from ldfe_jobs \n",
    "                where timestamp >= DATE_SUB(timestamp(current_date), INTERVAL 0 DAY);\n",
    "        \"\"\"\n",
    "\n",
    "result = pd.read_sql_query(query, con=conn)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3 - may need to test later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', 'eu-west-1')\n",
    "\n",
    "    s3bucket = 'rotaready-machine-learning'\n",
    "    \n",
    "    # create dataframe for job status\n",
    "    if job_start == True:\n",
    "        status_cols= ['timestamp', 'realm', 'site', 'jobtype']\n",
    "        s3key = 'ldfe/debug/inference/job_start.csv'\n",
    "    else: # job status report\n",
    "        status_cols= ['timestamp', 'realm', 'site', 'jobtype', 'status', 'note', 'fail reason']\n",
    "        # *check* the job status report should really only be exported after last client/site pair run, not after each of them\n",
    "        s3key = 'ldfe/debug/inference/job_status.csv'\n",
    "\n",
    "    status_df = pd.DataFrame([job_data], columns = status_cols)\n",
    "\n",
    "    # get existing data from S3\n",
    "    obj = s3.get_object(Bucket=s3bucket, Key=s3key)\n",
    "    current_data = pd.read_csv(BytesIO(obj['Body'].read())) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
